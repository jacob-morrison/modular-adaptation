import subprocess

def print_and_run(cmd):
    print(cmd)
    subprocess.run(cmd, shell=True)

baselines = [
    "llama_2_7b-tulu_all-science_none-seed_123",
    "llama_2_7b-tulu_match-science_500",
    "llama_2_7b-tulu_none-science_upsample",
    "tulu_2_7b_continued_ft-tulu_none-science_100",
    "llama_2_7b-tulu_all-science_none-seed_42",
    "llama_2_7b-tulu_none-science_100",
    "tulu_2_7b_continued_ft-tulu_none-science_1000",
    "llama_2_7b-tulu_all-science_none-seed_52830",
    "llama_2_7b-tulu_none-science_1000",
    "tulu_2_7b_continued_ft-tulu_none-science_200",
    "llama_2_7b-tulu_all-science_100",
    "llama_2_7b-tulu_all-science_upsample",
    "llama_2_7b-tulu_none-science_1000-seed_123",
    "tulu_2_7b_continued_ft-tulu_match-science_100",
    "tulu_2_7b_continued_ft-tulu_none-science_2500",
    "llama_2_7b-tulu_all-science_1000",
    "llama_2_7b-tulu_match-science_100",
    "llama_2_7b-tulu_none-science_1000-seed_52830",
    "tulu_2_7b_continued_ft-tulu_match-science_1000",
    "tulu_2_7b_continued_ft-tulu_none-science_500",
    "llama_2_7b-tulu_all-science_200",
    "llama_2_7b-tulu_match-science_1000",
    "llama_2_7b-tulu_none-science_200",
    "tulu_2_7b_continued_ft-tulu_match-science_200",
    "tulu_2_7b_continued_ft-tulu_none-science_upsample",
    "llama_2_7b-tulu_all-science_2500",
    "llama_2_7b-tulu_match-science_200",
    "llama_2_7b-tulu_none-science_2500",
    "tulu_2_7b_continued_ft-tulu_match-science_2500",
    "llama_2_7b-tulu_all-science_500",
    "llama_2_7b-tulu_match-science_2500",
    "llama_2_7b-tulu_none-science_500",
    "tulu_2_7b_continued_ft-tulu_match-science_500",
    "tulu_2_70b_continued_ft-tulu_none-science_1000",
    "llama_2_70b-tulu_none-science_1000",
    "tulu_2_70b_continued_ft-tulu_match-science_1000",
    "llama_2_70b-tulu_none-science_100",
    "llama_2_70b-tulu_all-science_none",
]

merged_models = [
    "dare_linear-llama_2_7b-tulu_all_0.1-science_1000_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_200_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_500_0.5",
    "slerp-llama_2_7b-tulu_all_0.8-science_100_0.2",
    "dare_linear-llama_2_7b-tulu_all_0.1-science_100_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_2500_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_upsample_0.5",
    "slerp-llama_2_7b-tulu_all_0.8-science_200_0.2",
    "dare_linear-llama_2_7b-tulu_all_0.1-science_200_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_500_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_1000_0.4",
    "slerp-llama_2_7b-tulu_all_0.8-science_2500_0.2",
    "dare_linear-llama_2_7b-tulu_all_0.1-science_2500_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_upsample_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_100_0.4",
    "slerp-llama_2_7b-tulu_all_0.8-science_500_0.2",
    "dare_linear-llama_2_7b-tulu_all_0.1-science_500_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_1000_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_200_0.4",
    "slerp-llama_2_7b-tulu_all_0.8-science_upsample_0.2",
    "dare_linear-llama_2_7b-tulu_all_0.1-science_upsample_0.9",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_100_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_2500_0.4",
    "slerp-llama_2_7b-tulu_all_0.9-science_1000_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_1000_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_200_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_500_0.4",
    "slerp-llama_2_7b-tulu_all_0.9-science_100_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_100_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_2500_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.6-science_upsample_0.4",
    "slerp-llama_2_7b-tulu_all_0.9-science_200_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_200_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_500_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_1000_0.3",
    "slerp-llama_2_7b-tulu_all_0.9-science_2500_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_2500_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.4-science_upsample_0.6",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_100_0.3",
    "slerp-llama_2_7b-tulu_all_0.9-science_500_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_500_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_1000_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_200_0.3",
    "slerp-llama_2_7b-tulu_all_0.9-science_upsample_0.1",
    "dare_linear-llama_2_7b-tulu_all_0.2-science_upsample_0.8",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_100_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_2500_0.3",
    "ties-llama_2_7b-tulu_all_0.1-science_1000_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_1000_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_200_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_500_0.3",
    "ties-llama_2_7b-tulu_all_0.1-science_100_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_100_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_2500_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.7-science_upsample_0.3",
    "ties-llama_2_7b-tulu_all_0.1-science_200_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_200_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_500_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_1000_0.2",
    "ties-llama_2_7b-tulu_all_0.1-science_2500_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_2500_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.5-science_upsample_0.5",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_100_0.2",
    "ties-llama_2_7b-tulu_all_0.1-science_500_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_500_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_1000_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_200_0.2",
    "ties-llama_2_7b-tulu_all_0.1-science_upsample_0.9",
    "dare_linear-llama_2_7b-tulu_all_0.3-science_upsample_0.7",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_100_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_2500_0.2",
    "ties-llama_2_7b-tulu_all_0.2-science_1000_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_1000_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_200_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_500_0.2",
    "ties-llama_2_7b-tulu_all_0.2-science_100_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_100_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_2500_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.8-science_upsample_0.2",
    "ties-llama_2_7b-tulu_all_0.2-science_200_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_200_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_500_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_1000_0.1",
    "ties-llama_2_7b-tulu_all_0.2-science_2500_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_2500_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.6-science_upsample_0.4",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_100_0.1",
    "ties-llama_2_7b-tulu_all_0.2-science_500_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_500_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_1000_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_200_0.1",
    "ties-llama_2_7b-tulu_all_0.2-science_upsample_0.8",
    "dare_linear-llama_2_7b-tulu_all_0.4-science_upsample_0.6",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_100_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_2500_0.1",
    "ties-llama_2_7b-tulu_all_0.3-science_1000_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_1000_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_200_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_500_0.1",
    "ties-llama_2_7b-tulu_all_0.3-science_100_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_100_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_2500_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.9-science_upsample_0.1",
    "ties-llama_2_7b-tulu_all_0.3-science_200_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_200_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_500_0.3",
    "slerp-llama_2_7b-tulu_all_0.1-science_100_0.9",
    "ties-llama_2_7b-tulu_all_0.3-science_2500_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_2500_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.7-science_upsample_0.3",
    "slerp-llama_2_7b-tulu_all_0.1-science_200_0.9",
    "ties-llama_2_7b-tulu_all_0.3-science_500_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_500_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_1000_0.2",
    "slerp-llama_2_7b-tulu_all_0.1-science_2500_0.9",
    "ties-llama_2_7b-tulu_all_0.3-science_upsample_0.7",
    "dare_linear-llama_2_7b-tulu_all_0.5-science_upsample_0.5",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_100_0.2",
    "slerp-llama_2_7b-tulu_all_0.1-science_500_0.9",
    "ties-llama_2_7b-tulu_all_0.4-science_1000_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_1000_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_200_0.2",
    "slerp-llama_2_7b-tulu_all_0.1-science_upsample_0.9",
    "ties-llama_2_7b-tulu_all_0.4-science_100_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_100_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_2500_0.2",
    "slerp-llama_2_7b-tulu_all_0.2-science_1000_0.8",
    "ties-llama_2_7b-tulu_all_0.4-science_200_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_200_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_500_0.2",
    "slerp-llama_2_7b-tulu_all_0.2-science_100_0.8",
    "ties-llama_2_7b-tulu_all_0.4-science_2500_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_2500_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.8-science_upsample_0.2",
    "slerp-llama_2_7b-tulu_all_0.2-science_200_0.8",
    "ties-llama_2_7b-tulu_all_0.4-science_500_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_500_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_1000_0.1",
    "slerp-llama_2_7b-tulu_all_0.2-science_2500_0.8",
    "ties-llama_2_7b-tulu_all_0.4-science_upsample_0.6",
    "dare_linear-llama_2_7b-tulu_all_0.6-science_upsample_0.4",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_100_0.1",
    "slerp-llama_2_7b-tulu_all_0.2-science_500_0.8",
    "ties-llama_2_7b-tulu_all_0.5-science_1000_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_1000_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_200_0.1",
    "slerp-llama_2_7b-tulu_all_0.2-science_upsample_0.8",
    "ties-llama_2_7b-tulu_all_0.5-science_100_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_100_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_2500_0.1",
    "slerp-llama_2_7b-tulu_all_0.3-science_1000_0.7",
    "ties-llama_2_7b-tulu_all_0.5-science_200_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_200_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_500_0.1",
    "slerp-llama_2_7b-tulu_all_0.3-science_100_0.7",
    "ties-llama_2_7b-tulu_all_0.5-science_2500_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_2500_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.9-science_upsample_0.1",
    "slerp-llama_2_7b-tulu_all_0.3-science_200_0.7",
    "ties-llama_2_7b-tulu_all_0.5-science_500_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_500_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_1000_0.9",
    "slerp-llama_2_7b-tulu_all_0.3-science_2500_0.7",
    "ties-llama_2_7b-tulu_all_0.5-science_upsample_0.5",
    "dare_linear-llama_2_7b-tulu_all_0.7-science_upsample_0.3",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_100_0.9",
    "slerp-llama_2_7b-tulu_all_0.3-science_500_0.7",
    "ties-llama_2_7b-tulu_all_0.6-science_1000_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_1000_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_200_0.9",
    "slerp-llama_2_7b-tulu_all_0.3-science_upsample_0.7",
    "ties-llama_2_7b-tulu_all_0.6-science_100_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_100_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_2500_0.9",
    "slerp-llama_2_7b-tulu_all_0.4-science_1000_0.6",
    "ties-llama_2_7b-tulu_all_0.6-science_200_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_200_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_500_0.9",
    "slerp-llama_2_7b-tulu_all_0.4-science_100_0.6",
    "ties-llama_2_7b-tulu_all_0.6-science_2500_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_2500_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.1-science_upsample_0.9",
    "slerp-llama_2_7b-tulu_all_0.4-science_200_0.6",
    "ties-llama_2_7b-tulu_all_0.6-science_500_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_500_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_1000_0.8",
    "slerp-llama_2_7b-tulu_all_0.4-science_2500_0.6",
    "ties-llama_2_7b-tulu_all_0.6-science_upsample_0.4",
    "dare_linear-llama_2_7b-tulu_all_0.8-science_upsample_0.2",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_100_0.8",
    "slerp-llama_2_7b-tulu_all_0.4-science_500_0.6",
    "ties-llama_2_7b-tulu_all_0.7-science_1000_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_1000_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_200_0.8",
    "slerp-llama_2_7b-tulu_all_0.4-science_upsample_0.6",
    "ties-llama_2_7b-tulu_all_0.7-science_100_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_100_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_2500_0.8",
    "slerp-llama_2_7b-tulu_all_0.5-science_1000_0.5",
    "ties-llama_2_7b-tulu_all_0.7-science_200_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_200_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_500_0.8",
    "slerp-llama_2_7b-tulu_all_0.5-science_100_0.5",
    "ties-llama_2_7b-tulu_all_0.7-science_2500_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_2500_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.2-science_upsample_0.8",
    "slerp-llama_2_7b-tulu_all_0.5-science_200_0.5",
    "ties-llama_2_7b-tulu_all_0.7-science_500_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_500_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_1000_0.7",
    "slerp-llama_2_7b-tulu_all_0.5-science_2500_0.5",
    "ties-llama_2_7b-tulu_all_0.7-science_upsample_0.3",
    "dare_linear-llama_2_7b-tulu_all_0.9-science_upsample_0.1",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_100_0.7",
    "slerp-llama_2_7b-tulu_all_0.5-science_500_0.5",
    "ties-llama_2_7b-tulu_all_0.8-science_1000_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_1000_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_200_0.7",
    "slerp-llama_2_7b-tulu_all_0.5-science_upsample_0.5",
    "ties-llama_2_7b-tulu_all_0.8-science_100_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_100_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_2500_0.7",
    "slerp-llama_2_7b-tulu_all_0.6-science_1000_0.4",
    "ties-llama_2_7b-tulu_all_0.8-science_200_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_200_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_500_0.7",
    "slerp-llama_2_7b-tulu_all_0.6-science_100_0.4",
    "ties-llama_2_7b-tulu_all_0.8-science_2500_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_2500_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.3-science_upsample_0.7",
    "slerp-llama_2_7b-tulu_all_0.6-science_200_0.4",
    "ties-llama_2_7b-tulu_all_0.8-science_500_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_500_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_1000_0.6",
    "slerp-llama_2_7b-tulu_all_0.6-science_2500_0.4",
    "ties-llama_2_7b-tulu_all_0.8-science_upsample_0.2",
    "dare_ties-llama_2_7b-tulu_all_0.1-science_upsample_0.9",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_100_0.6",
    "slerp-llama_2_7b-tulu_all_0.6-science_500_0.4",
    "ties-llama_2_7b-tulu_all_0.9-science_1000_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_1000_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_200_0.6",
    "slerp-llama_2_7b-tulu_all_0.6-science_upsample_0.4",
    "ties-llama_2_7b-tulu_all_0.9-science_100_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_100_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_2500_0.6",
    "slerp-llama_2_7b-tulu_all_0.7-science_1000_0.3",
    "ties-llama_2_7b-tulu_all_0.9-science_200_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_200_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_500_0.6",
    "slerp-llama_2_7b-tulu_all_0.7-science_100_0.3",
    "ties-llama_2_7b-tulu_all_0.9-science_2500_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_2500_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.4-science_upsample_0.6",
    "slerp-llama_2_7b-tulu_all_0.7-science_200_0.3",
    "ties-llama_2_7b-tulu_all_0.9-science_500_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_500_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_1000_0.5",
    "slerp-llama_2_7b-tulu_all_0.7-science_2500_0.3",
    "ties-llama_2_7b-tulu_all_0.9-science_upsample_0.1",
    "dare_ties-llama_2_7b-tulu_all_0.2-science_upsample_0.8",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_100_0.5",
    "slerp-llama_2_7b-tulu_all_0.7-science_500_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_1000_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_200_0.5",
    "slerp-llama_2_7b-tulu_all_0.7-science_upsample_0.3",
    "dare_ties-llama_2_7b-tulu_all_0.3-science_100_0.7",
    "linear_weighted-llama_2_7b-tulu_all_0.5-science_2500_0.5",
    "slerp-llama_2_7b-tulu_all_0.8-science_1000_0.2",
]

for model in merged_models:
    beaker_name = "jacobm/" + model
    new_beaker_name = f"{model}_4096"
    print_and_run("mkdir tmp_model_directory")
    print_and_run(f"beaker dataset fetch {beaker_name} -o tmp_model_directory/")
    print_and_run("rm tmp_model_directory/config.json tmp_model_directory/generation_config.json tmp_model_directory/special_tokens_map.json tmp_model_directory/tokenizer.model tmp_model_directory/tokenizer_config.json")
    print_and_run("ls tmp_model_directory/")
    print_and_run("cp llama_tokenizer_4k/* tmp_model_directory/")
    print_and_run("ls tmp_model_directory/")
    print_and_run(f"beaker dataset create tmp_model_directory/ -n {new_beaker_name} -w ai2/modular-adaptation-science")
    print_and_run("rm -rf tmp_model_directory")